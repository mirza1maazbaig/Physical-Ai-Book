# Data Model: Vision-Language-Action (VLA) System

**Module**: Module 4: Vision-Language-Action (VLA)
**Date**: 2025-12-16

## Overview

This document defines the data models for the Vision-Language-Action system, including voice processing, cognitive planning, and action execution components.

## Core Entities

### VoiceCommand
- **Description**: Represents a voice command captured from the user
- **Fields**:
  - `id` (string): Unique identifier for the command
  - `audio_data` (bytes): Raw audio data from microphone
  - `transcript` (string): Transcribed text from audio
  - `timestamp` (datetime): When the command was captured
  - `confidence` (float): Confidence score of the transcription (0.0-1.0)
  - `language` (string): Language of the command

### CognitivePlan
- **Description**: Represents a high-level plan generated by the LLM from a voice command
- **Fields**:
  - `id` (string): Unique identifier for the plan
  - `voice_command_id` (string): Reference to the original voice command
  - `high_level_goal` (string): The original command ("Clean the room")
  - `action_sequence` (list of ActionStep): Ordered list of actions to execute
  - `context` (dict): Additional context for the plan execution
  - `created_at` (datetime): When the plan was generated
  - `status` (string): Current status (pending, executing, completed, failed)

### ActionStep
- **Description**: A single step in the cognitive plan
- **Fields**:
  - `id` (string): Unique identifier for the action step
  - `plan_id` (string): Reference to the parent cognitive plan
  - `action_type` (string): Type of action (navigate, look_for, pick_up, etc.)
  - `parameters` (dict): Action-specific parameters
  - `priority` (int): Priority of this action (1-10)
  - `estimated_duration` (float): Estimated time to complete (in seconds)
  - `status` (string): Current status (pending, executing, completed, failed)
  - `result` (dict): Result of action execution (if completed)

### ROS2Action
- **Description**: A ROS 2 action that corresponds to an ActionStep
- **Fields**:
  - `id` (string): Unique identifier for the ROS 2 action
  - `action_step_id` (string): Reference to the corresponding action step
  - `node_name` (string): Name of the ROS 2 node to execute the action
  - `action_name` (string): Name of the ROS 2 action (e.g., "navigate_to_pose")
  - `action_parameters` (dict): Parameters for the ROS 2 action
  - `status` (string): Current status (pending, executing, completed, failed)
  - `result` (dict): Result from the ROS 2 action execution

### PerceptionData
- **Description**: Data from vision systems used for action planning
- **Fields**:
  - `id` (string): Unique identifier for the perception data
  - `timestamp` (datetime): When the data was captured
  - `sensor_type` (string): Type of sensor (camera, lidar, etc.)
  - `object_list` (list of ObjectInfo): List of detected objects
  - `environment_map` (dict): Map of the environment
  - `frame_id` (string): Coordinate frame of the data

### ObjectInfo
- **Description**: Information about a detected object
- **Fields**:
  - `id` (string): Unique identifier for the object
  - `name` (string): Name or type of object (chair, cup, etc.)
  - `position` (dict): 3D position (x, y, z)
  - `orientation` (dict): 3D orientation (quaternion)
  - `dimensions` (dict): Size of the object (width, height, depth)
  - `confidence` (float): Confidence of detection (0.0-1.0)
  - `grasp_points` (list of dict): Suggested grasp points for manipulation

## Relationships

- VoiceCommand → CognitivePlan (one-to-many): One voice command generates one cognitive plan
- CognitivePlan → ActionStep (one-to-many): One plan contains multiple action steps
- ActionStep → ROS2Action (one-to-one): Each action step maps to a ROS 2 action
- ActionStep → PerceptionData (many-to-many): Action steps may use perception data
- PerceptionData → ObjectInfo (one-to-many): Perception data contains multiple objects

## Validation Rules

- VoiceCommand.transcript must not be empty
- CognitivePlan.action_sequence must contain at least one ActionStep
- ActionStep.priority must be between 1 and 10
- ActionStep.parameters must match the expected schema for the action_type
- ObjectInfo.position must contain x, y, z coordinates
- ObjectInfo.confidence must be between 0.0 and 1.0